{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import random\n",
    "import xml.etree.cElementTree as et\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from networkx.algorithms import bipartite\n",
    "import json\n",
    "import random\n",
    "from sklearn import metrics\n",
    "from collections import deque\n",
    "import pandas as pd"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing JSON File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_data = json.load(open('./products_data.json'))\n",
    "data = file_data['category_results']\n",
    "attribute_data = json.load(open('./data.json', encoding='utf-8'))\n",
    "asin_to_name = {}\n",
    "\n",
    "for prd in data:\n",
    "    asin_to_name[prd['asin']] = prd['title']\n",
    "\n",
    "print(len(list(asin_to_name.keys())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "products = []\n",
    "attributes = []\n",
    "edges = []\n",
    "\n",
    "attribute_keys = {}\n",
    "\n",
    "for prd in data:\n",
    "    products.append(prd['asin'])\n",
    "    asin = prd['asin']\n",
    "    # if attribute_data[asin]['product']['specifications'] is None:\n",
    "    #     continue\n",
    "    product_specs = attribute_data[asin]['product']['specifications']\n",
    "    for spec in product_specs:\n",
    "        attribute_name = spec['name']\n",
    "        edges.append((asin, attribute_name))\n",
    "        attribute_keys[spec['name']] = 1\n",
    "\n",
    "attributes = list(attribute_keys.keys())\n",
    "print(\"Number of products\", len(products), sep='\\n')\n",
    "print(\"Number of attributes\", len(attributes), sep='\\n')\n",
    "print(\"Number of edges\", len(edges), sep='\\n')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Making nodes Unique by giving them to a numerical index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_swapped = False\n",
    "if len(attributes) < len(products):\n",
    "  temp = products.copy()\n",
    "  products = attributes.copy()\n",
    "  attributes = temp.copy()\n",
    "  is_swapped = True\n",
    "\n",
    "original_products = products.copy()\n",
    "original_attributes = attributes.copy()\n",
    "PRODUCTS_MAP = {}\n",
    "ATTRIBUTES_MAP = {}\n",
    "EDGES_MAP = {}\n",
    "offset = len(products)\n",
    "\n",
    "for idx, x in enumerate(products):\n",
    "  PRODUCTS_MAP[x] = idx\n",
    "  products[idx] = idx\n",
    "\n",
    "for idx, x in enumerate(attributes):\n",
    "  ATTRIBUTES_MAP[x] = idx + offset\n",
    "  attributes[idx] = idx + offset\n",
    "\n",
    "for idx, x in enumerate(edges):\n",
    "  if is_swapped:\n",
    "    edges[idx] = (ATTRIBUTES_MAP[x[0]], PRODUCTS_MAP[x[1]])\n",
    "  else:\n",
    "    edges[idx] = (PRODUCTS_MAP[x[0]], ATTRIBUTES_MAP[x[1]])\n",
    "\n",
    "print('SET 1: ', products)\n",
    "print('SET 2: ', attributes)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making a Bipartite Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GRAPH = nx.Graph()\n",
    "\n",
    "GRAPH.add_nodes_from(products, bipartite=0)\n",
    "GRAPH.add_nodes_from(attributes, bipartite=1)\n",
    "# top = nx.bipartite.sets(GRAPH)[0]\n",
    "pos = nx.bipartite_layout(GRAPH, products)\n",
    "\n",
    "\n",
    "GRAPH.add_edges_from(edges)\n",
    "bipartite.is_bipartite(GRAPH)\n",
    "nx.draw_networkx(GRAPH, pos = nx.drawing.layout.bipartite_layout(GRAPH, products), width = 2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adjacency Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adjacency matrix\n",
    "adj = nx.adjacency_matrix(GRAPH)\n",
    "adj = adj.toarray()\n",
    "\n",
    "U_NODES = products\n",
    "V_NODES = attributes\n",
    "\n",
    "# plot adjacency matrix\n",
    "plt.title('Adjacency Matrix')\n",
    "plt.imshow(adj, cmap='Greys')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot graph visualisation\n",
    "nx.draw(GRAPH, with_labels=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TOP `n` ATTRIBUTES FOR EACH PRODUCT: -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TOP_N_PREDICTIONS = {}\n",
    "\n",
    "def top_n_predictions(n, FINAL_RESULT):\n",
    "    for pred in FINAL_RESULT:\n",
    "        asin = list(pred.keys())[0][0]\n",
    "        attribute = list(pred.keys())[0][1]\n",
    "        similarity_value = pred[(asin, attribute)]\n",
    "        if is_swapped:\n",
    "            temp = asin\n",
    "            asin = attribute\n",
    "            attribute = temp\n",
    "\n",
    "        if TOP_N_PREDICTIONS.get(asin) is None:\n",
    "            TOP_N_PREDICTIONS[asin] = {'name': asin_to_name[asin], 'predicted_attributes': []}\n",
    "        if len(TOP_N_PREDICTIONS[asin]['predicted_attributes']) == n:\n",
    "            continue\n",
    "        TOP_N_PREDICTIONS[asin]['predicted_attributes'].append({attribute: similarity_value})\n",
    "    \n",
    "    return TOP_N_PREDICTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PREDICTIONS_ABOVE_K = {}\n",
    "\n",
    "def top_predictions_above_threshold(k, FINAL_RESULT):\n",
    "    for pred in FINAL_RESULT:\n",
    "        asin = list(pred.keys())[0][0]\n",
    "        attribute = list(pred.keys())[0][1]\n",
    "        similarity_value = pred[(asin, attribute)]\n",
    "        if is_swapped:\n",
    "            temp = asin\n",
    "            asin = attribute\n",
    "            attribute = temp\n",
    "\n",
    "        if PREDICTIONS_ABOVE_K.get(asin) is None:\n",
    "            PREDICTIONS_ABOVE_K[asin] = {'name': asin_to_name[asin], 'predicted_attributes': []}\n",
    "        if similarity_value < k:\n",
    "            continue\n",
    "        PREDICTIONS_ABOVE_K[asin]['predicted_attributes'].append({attribute: similarity_value})\n",
    "    \n",
    "    return PREDICTIONS_ABOVE_K"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PLP FUNCTION: -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PLP_ALGO2(GRAPH):\n",
    "    global products\n",
    "    global attributes\n",
    "    # Construct the set of all patterns\n",
    "    U_PROJ_PAIRS = []\n",
    "    adj = nx.adjacency_matrix(GRAPH)\n",
    "    adj = adj.toarray()\n",
    "\n",
    "    for B in U_NODES:\n",
    "        temp = [n for n in GRAPH.neighbors(B)]\n",
    "        for x in temp:\n",
    "            temp1 = [n for n in GRAPH.neighbors(x)]\n",
    "            for C in temp1:\n",
    "                if B != C and (C, B) not in U_PROJ_PAIRS and (B, C) not in U_PROJ_PAIRS:\n",
    "                    U_PROJ_PAIRS.append((B, C))\n",
    "\n",
    "    U_PROJ_PAIRS = set(U_PROJ_PAIRS)\n",
    "\n",
    "\n",
    "    # adjList :)\n",
    "    adjList = [[] for i in range(len(U_NODES) + len(V_NODES) + 300)]\n",
    "\n",
    "    for node in U_NODES:\n",
    "        for nbr in adj[node]:\n",
    "            if not nbr:\n",
    "                continue\n",
    "            adjList[node].append(nbr)\n",
    "\n",
    "    for node in V_NODES:\n",
    "        for nbr in adj[node]:\n",
    "            if not nbr:\n",
    "                continue\n",
    "            adjList[node].append(nbr)\n",
    "\n",
    "\n",
    "    def dfs(depth, node, V, maxDepth):\n",
    "        if V[node]:\n",
    "            return 0\n",
    "        qu = deque()\n",
    "        qu.append(node)\n",
    "        V[node] = True\n",
    "        res = 1\n",
    "        while not qu and depth <= maxDepth:\n",
    "            sz = len(qu)\n",
    "\n",
    "            for i in range(sz):\n",
    "                front = qu.popleft()\n",
    "                V[front] = 1\n",
    "                for nbr in adjList[front]:\n",
    "                    if V[nbr]:\n",
    "                        continue\n",
    "                    if depth%2 != 0:\n",
    "                        res += 1\n",
    "                    qu.append(nbr)\n",
    "\n",
    "            depth += 1\n",
    "\n",
    "        return res\n",
    "                \n",
    "\n",
    "    # Calculate the weight of each pattern\n",
    "    weight = {}\n",
    "    for pair in U_PROJ_PAIRS:\n",
    "        A = pair[0]\n",
    "        B = pair[1]\n",
    "        \n",
    "        deg_A = GRAPH.degree(A)\n",
    "        deg_B = GRAPH.degree(B)\n",
    "        \n",
    "        neighbour_A = []\n",
    "        neighbour_B = []\n",
    "        for i in GRAPH.neighbors(A):\n",
    "            neighbour_A.append(i)\n",
    "        for i in GRAPH.neighbors(B):\n",
    "            neighbour_B.append(i)\n",
    "\n",
    "        neightbour_intersect = list(set(neighbour_A).intersection(neighbour_B))\n",
    "        sum = 0\n",
    "        maxi = 0\n",
    "        V = [False for i in range(len(U_NODES) + len(V_NODES) + 300)]\n",
    "        for intersect in neightbour_intersect:\n",
    "            V[A] = True\n",
    "            V[B] = True\n",
    "            maxDepth = 3000\n",
    "            denom = dfs(0, intersect, V, maxDepth) + 2\n",
    "            sum = sum + 1/denom\n",
    "            maxi = max(maxi, sum)\n",
    "        sum = sum%(maxi+1)\n",
    "        # print(\"sum: \", sum, sep=\"\\n\")\n",
    "        weight[pair] = maxi * (2/(deg_A+deg_B))\n",
    "\n",
    "    # print(weight, sep=\"\\n\")\n",
    "    # print(len(weight))\n",
    "\n",
    "\n",
    "    # U PROJECTED GRAPH\n",
    "\n",
    "    U_PROJ_GRAPH = nx.projected_graph(GRAPH, U_NODES)\n",
    "\n",
    "    # get adjacency matrix\n",
    "    adj = nx.adjacency_matrix(U_PROJ_GRAPH)\n",
    "    adj = adj.toarray()\n",
    "    \n",
    "    # # plot adjacency matrix\n",
    "    # plt.title(' Adjacency Matrix')\n",
    "    # plt.imshow(adj, cmap='Greys')\n",
    "    # plt.show()\n",
    "\n",
    "    # # plot graph visualisation\n",
    "    # plt.figure(figsize=(10,10)) \n",
    "    # plt.title(\"Projected Graph\")\n",
    "    # nx.draw(U_PROJ_GRAPH, with_labels=True)\n",
    "    # plt.show()\n",
    "\n",
    "\n",
    "    # Calculate the connectivity of CNPs\n",
    "    U_PROJ_GRAPH_NODES = U_PROJ_GRAPH.nodes()\n",
    "    mat = {}\n",
    "    linked_mat = {}\n",
    "\n",
    "    for node in U_PROJ_GRAPH_NODES:\n",
    "        for nbr in U_PROJ_GRAPH.neighbors(node):\n",
    "            for nbrNode in GRAPH.neighbors(nbr):\n",
    "                bipartiteNodeNeighbors = []\n",
    "\n",
    "                for node_neighbour in GRAPH.neighbors(node):\n",
    "                    bipartiteNodeNeighbors.append(node_neighbour)\n",
    "\n",
    "                CNP = (node, nbrNode)\n",
    "                if nbrNode not in bipartiteNodeNeighbors:\n",
    "\n",
    "                    if mat.get(CNP) is None:\n",
    "                        mat[CNP] = 0\n",
    "\n",
    "                    if weight.get((node, nbr)) is None:\n",
    "                        weight[(node, nbr)] = 0\n",
    "\n",
    "                    mat[CNP] = mat.get(CNP) + weight.get((node, nbr))\n",
    "                else:\n",
    "                    if linked_mat.get(CNP) is None:\n",
    "                        linked_mat[CNP] = 0\n",
    "\n",
    "                    if weight.get((node, nbr)) is None:\n",
    "                        weight[(node, nbr)] = 0\n",
    "\n",
    "                    linked_mat[CNP] = linked_mat.get(CNP) + weight.get((node, nbr))\n",
    "\n",
    "\n",
    "\n",
    "    keys = list(mat.keys())\n",
    "    values = list(mat.values())\n",
    "    sorted_value_index = np.argsort(values)\n",
    "    sorted_mat = {keys[i]: values[i] for i in sorted_value_index}\n",
    "\n",
    "    FINAL_RESULT = []\n",
    "    RESULT_IMP = []\n",
    "    sum = 0\n",
    "\n",
    "    for pr in sorted_mat:\n",
    "        temp = {}\n",
    "        temp[(original_products[pr[0]], original_attributes[pr[1] - offset])] = sorted_mat[pr]\n",
    "        RESULT_IMP.append((pr[0], pr[1], sorted_mat[pr]))\n",
    "        FINAL_RESULT.append(temp)\n",
    "        sum += sorted_mat[pr]\n",
    "\n",
    "    FINAL_RESULT.reverse()\n",
    "    RESULT_IMP.reverse()\n",
    "\n",
    "    if is_swapped:\n",
    "        temp = products.copy()\n",
    "        products = attributes.copy()\n",
    "        attributes = temp.copy()\n",
    "\n",
    "    \n",
    "    # print(\"total Predictions: \", FINAL_RESULT)\n",
    "    # print(\"Top 10 predictions: \", FINAL_RESULT[:10])\n",
    "    return [RESULT_IMP, FINAL_RESULT, mat, linked_mat]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PLP_ALGO1(GRAPH):\n",
    "    global products\n",
    "    global attributes\n",
    "    # Construct the set of all patterns\n",
    "    U_PROJ_PAIRS = []\n",
    "\n",
    "    for B in U_NODES:\n",
    "        temp = [n for n in GRAPH.neighbors(B)]\n",
    "        for x in temp:\n",
    "            temp1 = [n for n in GRAPH.neighbors(x)]\n",
    "            for C in temp1:\n",
    "                if B != C and (C, B) not in U_PROJ_PAIRS and (B, C) not in U_PROJ_PAIRS:\n",
    "                    U_PROJ_PAIRS.append((B, C))\n",
    "\n",
    "    U_PROJ_PAIRS = set(U_PROJ_PAIRS)\n",
    "        \n",
    "\n",
    "    # Calculate the weight of each pattern\n",
    "    weight = {}\n",
    "    for pair in U_PROJ_PAIRS:\n",
    "        A = pair[0]\n",
    "        B = pair[1]\n",
    "        \n",
    "        deg_A = GRAPH.degree(A)\n",
    "        deg_B = GRAPH.degree(B)\n",
    "        \n",
    "        neighbour_A = []\n",
    "        neighbour_B = []\n",
    "        for i in GRAPH.neighbors(A):\n",
    "            neighbour_A.append(i)\n",
    "        for i in GRAPH.neighbors(B):\n",
    "            neighbour_B.append(i)\n",
    "\n",
    "        neightbour_intersect = list(set(neighbour_A).intersection(neighbour_B))\n",
    "        sum = 0\n",
    "        for intersect in neightbour_intersect:\n",
    "            sum += 1/(GRAPH.degree(intersect)+1)\n",
    "\n",
    "        weight[pair] = sum * (2/(deg_A+deg_B))\n",
    "\n",
    "    # print(weight, sep=\"\\n\")\n",
    "    # print(len(weight))\n",
    "\n",
    "\n",
    "    # U PROJECTED GRAPH\n",
    "\n",
    "    U_PROJ_GRAPH = nx.projected_graph(GRAPH, U_NODES)\n",
    "\n",
    "    # get adjacency matrix\n",
    "    adj = nx.adjacency_matrix(U_PROJ_GRAPH)\n",
    "    adj = adj.toarray()\n",
    "\n",
    "    # plot adjacency matrix\n",
    "    plt.title('Projected Graph Adjacency Matrix')\n",
    "    plt.imshow(adj, cmap='Greys')\n",
    "    plt.show()\n",
    "\n",
    "    # # plot graph visualisation\n",
    "    # plt.figure(figsize=(10,10)) \n",
    "    # plt.title(\"Projected Graph\")\n",
    "    # nx.draw(U_PROJ_GRAPH, with_labels=True)\n",
    "    # plt.show()\n",
    "\n",
    "    # Calculate the connectivity of CNPs\n",
    "    U_PROJ_GRAPH_NODES = U_PROJ_GRAPH.nodes()\n",
    "    mat = {}\n",
    "    linked_mat = {}\n",
    "\n",
    "    for node in U_PROJ_GRAPH_NODES:\n",
    "        for nbr in U_PROJ_GRAPH.neighbors(node):\n",
    "            for nbrNode in GRAPH.neighbors(nbr):\n",
    "                bipartiteNodeNeighbors = []\n",
    "\n",
    "                for node_neighbour in GRAPH.neighbors(node):\n",
    "                    bipartiteNodeNeighbors.append(node_neighbour)\n",
    "\n",
    "                CNP = (node, nbrNode)\n",
    "                if nbrNode not in bipartiteNodeNeighbors:\n",
    "\n",
    "                    if mat.get(CNP) is None:\n",
    "                        mat[CNP] = 0\n",
    "\n",
    "                    if weight.get((node, nbr)) is None:\n",
    "                        weight[(node, nbr)] = 0\n",
    "\n",
    "                    mat[CNP] = mat.get(CNP) + weight.get((node, nbr))\n",
    "                else:\n",
    "                    if linked_mat.get(CNP) is None:\n",
    "                        linked_mat[CNP] = 0\n",
    "\n",
    "                    if weight.get((node, nbr)) is None:\n",
    "                        weight[(node, nbr)] = 0\n",
    "\n",
    "                    linked_mat[CNP] = linked_mat.get(CNP) + weight.get((node, nbr))\n",
    "\n",
    "\n",
    "\n",
    "    keys = list(mat.keys())\n",
    "    values = list(mat.values())\n",
    "    sorted_value_index = np.argsort(values)\n",
    "    sorted_mat = {keys[i]: values[i] for i in sorted_value_index}\n",
    "\n",
    "    FINAL_RESULT = []\n",
    "    RESULT_IMP = []\n",
    "    sum = 0\n",
    "\n",
    "    for pr in sorted_mat:\n",
    "        temp = {}\n",
    "        temp[(original_products[pr[0]], original_attributes[pr[1] - offset])] = sorted_mat[pr]\n",
    "        RESULT_IMP.append((pr[0], pr[1], sorted_mat[pr]))\n",
    "        FINAL_RESULT.append(temp)\n",
    "        sum += sorted_mat[pr]\n",
    "\n",
    "    FINAL_RESULT.reverse()\n",
    "    RESULT_IMP.reverse()\n",
    "\n",
    "    if is_swapped:\n",
    "        temp = products.copy()\n",
    "        products = attributes.copy()\n",
    "        attributes = temp.copy()\n",
    "\n",
    "    \n",
    "    # print(\"total Predictions: \", FINAL_RESULT)\n",
    "    # print(\"Top 10 predictions: \", FINAL_RESULT[:10])\n",
    "    return [RESULT_IMP, FINAL_RESULT, mat, linked_mat]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_link_prediction(pred, train_G, test_G, k=10):\n",
    "    # Create arrays of true labels (y_true) and predicted scores (y_score)\n",
    "    y_true = [test_G.has_edge(p[0], p[1]) for p in pred]\n",
    "    y_score = [p[2] for p in pred]\n",
    "\n",
    "    # Compute AUC-ROC score\n",
    "    auc_roc = metrics.roc_auc_score(y_true, y_score) \n",
    "\n",
    "    # Compute AUC-PRC score\n",
    "    precision, recall, thresholds = metrics.precision_recall_curve(y_true, y_score)\n",
    "    auc_prc = metrics.auc(recall, precision)\n",
    "\n",
    "    # Compute precision at k\n",
    "    y_pred = [1 if p[2] > thresholds[k] else 0 for p in pred]\n",
    "    precision_at_k = metrics.precision_score(y_true, y_pred)\n",
    "\n",
    "    # Compute F1 score\n",
    "    f1_score = metrics.f1_score(y_true, y_pred)\n",
    "\n",
    "    # Print evaluation metrics\n",
    "    print(\"AUC-ROC score: {:.4f}\".format(auc_roc))\n",
    "    print(\"AUC-PRC score: {:.4f}\".format(auc_prc))\n",
    "    print(\"Precision at k = {}: {:.4f}\".format(k, precision_at_k))\n",
    "    print(\"F1 score: {:.4f}\".format(f1_score))\n",
    "\n",
    "    # Plot auc roc graph\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2)\n",
    "    ax1.set_xlabel('Recall')\n",
    "    ax1.set_ylabel('Precision')\n",
    "    ax1.plot(recall, precision)\n",
    "    ax1.set_title(\"Precision-Recall Curve\")\n",
    "    # plt.title('Precision-Recall Curve')\n",
    "\n",
    "    # Compute AUC-ROC score\n",
    "    fpr, tpr, thresholds = metrics.roc_curve(y_true, y_score) \n",
    "    ax2.plot(fpr, tpr)\n",
    "    ax2.set_title(\"ROC Curve, AUC = {:.2f}\".format(auc_roc))\n",
    "    plt.show()\n",
    "\n",
    "    return auc_roc, auc_prc, precision_at_k, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RUN(data1, data2, idx):\n",
    "    # Remove 30% of the edges\n",
    "    proportion_edges = 0.3\n",
    "    # this is our test set\n",
    "    edge_subset = random.sample(GRAPH.edges(), int(proportion_edges * GRAPH.number_of_edges()))\n",
    "    # Create a copy of the graph and remove the edges\n",
    "    G_train = GRAPH.copy()\n",
    "    G_train.remove_edges_from(edge_subset)\n",
    "\n",
    "    # adjacency matrix\n",
    "    A_train = nx.adjacency_matrix(G_train)\n",
    "    A_train = A_train.toarray()\n",
    "\n",
    "    plt.figure(figsize=(10,10)) \n",
    "    plt.title(\"Train Graph\")\n",
    "    nx.draw(G_train, pos, with_labels=True)\n",
    "    plt.show()\n",
    "\n",
    "    \"\"\"\n",
    "    TEST\n",
    "    \"\"\"\n",
    "    G_test = nx.Graph()\n",
    "    G_test.add_edges_from(edge_subset)\n",
    "\n",
    "    plt.figure(figsize=(10,10)) \n",
    "    plt.title(\"Test Graph\")\n",
    "    nx.draw(G_test, pos, with_labels=True)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "    G_pred = nx.Graph()\n",
    "    [RESULT1, FINAL_RESULT1, mat, linked_mat] = PLP_ALGO1(G_train)\n",
    "    [RESULT2, FINAL_RESULT2, mat, linked_mat] = PLP_ALGO2(G_train)\n",
    "    print(FINAL_RESULT1 == FINAL_RESULT2, RESULT1 == RESULT2)\n",
    "\n",
    "    G_pred.add_weighted_edges_from(RESULT1)\n",
    "    G_pred.add_weighted_edges_from(RESULT2)\n",
    "\n",
    "    print(\"for algo1: -\", sep=\"\\n\")\n",
    "    [auc_roc1, auc_prc1, precision_at_k1, f1_score1] = evaluate_link_prediction(RESULT1, G_train, G_test, 3)\n",
    "    print(\"for algo2: -\", sep=\"\\n\")\n",
    "    [auc_roc2, auc_prc2, precision_at_k2, f1_score2] = evaluate_link_prediction(RESULT2, G_train, G_test, 3)\n",
    "    \n",
    "    data1[\"auc_roc\"].append(auc_roc1 * 100)\n",
    "    data1[\"auc_prc\"].append(auc_prc1 * 100)\n",
    "    \n",
    "    data2[\"auc_roc\"].append(auc_roc2 * 100)\n",
    "    data2[\"auc_prc\"].append(auc_prc2 * 100)\n",
    "    \n",
    "    \n",
    "    TOP_N_PREDICTIONS1 = top_n_predictions(5, FINAL_RESULT1)\n",
    "    TOP_N_PREDICTIONS2 = top_n_predictions(5, FINAL_RESULT2)\n",
    "\n",
    "    file_name1 = \"results_predictions_algo1/result{}.json\".format(idx)\n",
    "    f = open(file_name1, \"w\")\n",
    "    \n",
    "    # Serializing json  \n",
    "    TOP_N_PREDICTIONS1 = json.dumps(TOP_N_PREDICTIONS1, indent = 4) \n",
    "    f.write(TOP_N_PREDICTIONS1)\n",
    "\n",
    "    file_name2 = \"results_predictions_algo2/result{}.json\".format(idx)\n",
    "    f = open(file_name2, \"w\")\n",
    "    \n",
    "    # Serializing json  \n",
    "    TOP_N_PREDICTIONS2 = json.dumps(TOP_N_PREDICTIONS2, indent = 4) \n",
    "    f.write(TOP_N_PREDICTIONS2)\n",
    "\n",
    "\n",
    "\n",
    "    # PREDICTIONS_ABOVE_K1 = top_predictions_above_threshold(0.6, FINAL_RESULT1)\n",
    "    # PREDICTIONS_ABOVE_K2 = top_predictions_above_threshold(0.6, FINAL_RESULT2)\n",
    "\n",
    "    # file_name1 = \"results_predictions_k_algo1/result{}.json\".format(idx)\n",
    "    # f = open(file_name1, \"w\")\n",
    "    \n",
    "    # # Serializing json  \n",
    "    # PREDICTIONS_ABOVE_K1 = json.dumps(PREDICTIONS_ABOVE_K1, indent = 4) \n",
    "    # f.write(PREDICTIONS_ABOVE_K1)\n",
    "\n",
    "    # file_name2 = \"results_predictions_k_algo2/result{}.json\".format(idx)\n",
    "    # f = open(file_name2, \"w\")\n",
    "    \n",
    "    # # Serializing json  \n",
    "    # PREDICTIONS_ABOVE_K2 = json.dumps(PREDICTIONS_ABOVE_K2, indent = 4) \n",
    "    # f.write(PREDICTIONS_ABOVE_K2)\n",
    "\n",
    "    # # visualise adjacency matrix\n",
    "    # Apred = nx.adjacency_matrix(G_pred)\n",
    "    # Apred = Apred.toarray()\n",
    "    # plt.imshow(Apredcmaps, cmap='Greys')\n",
    "    # plt.show()\n",
    "\n",
    "\n",
    "    # plt.figure(figsize=(10,10)) \n",
    "    # plt.title(\"Prediction Graph\")\n",
    "    # nx.draw(G_pred, pos, with_labels=True)\n",
    "    # plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df1 = pd.DataFrame({'auc_roc': [], 'auc_prc': []})\n",
    "# df2 = pd.DataFrame({'auc_roc': [], 'auc_prc': []})\n",
    "data1 = {'auc_roc': [], 'auc_prc': []}\n",
    "data2 = {'auc_roc': [], 'auc_prc': []}\n",
    "for i in range(3):\n",
    "    print(i+1, sep=\"\\n\")\n",
    "    RUN(data1, data2, i+1)\n",
    "    print(\"----------------------------------------END----------------------------------------\\n\")\n",
    "\n",
    "df1 = pd.DataFrame(data1)\n",
    "df2 = pd.DataFrame(data2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
